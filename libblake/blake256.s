	.section	__TEXT,__text,regular,pure_instructions
	.globl	_rounds
	.align	4, 0x90
_rounds:
	pushl	%ebp
	movl	%esp, %ebp
	pushl	%ebx
	pushl	%edi
	pushl	%esi
	subl	$28, %esp
	call	L1$pb
L1$pb:
	popl	%eax
	movl	8(%ebp), %ecx
	movl	%ecx, -16(%ebp)
	## InlineAsm Start
	movl  %ebx, -20(%ebp)
	## InlineAsm End
	## InlineAsm Start
	movl  %esi, -24(%ebp)
	## InlineAsm End
	## InlineAsm Start
	movl  %edi, -28(%ebp)
	## InlineAsm End
	## InlineAsm Start
	movl  %eax, -32(%ebp)
	## InlineAsm End
	## InlineAsm Start
	movl  %ecx, -36(%ebp)
	## InlineAsm End
	## InlineAsm Start
	movl  %edx, -40(%ebp)
	## InlineAsm End
	movl	_v0-L1$pb(%eax), %ecx
	## InlineAsm Start
	movl (%ecx), %eax
	## InlineAsm End
	movl	_v4-L1$pb(%eax), %ecx
        ## InlineAsm Start
	movl (%ecx), %ebx
	## InlineAsm End

	## InlineAsm Start
	movl -32(%ebp), %eax
	## InlineAsm End
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	_sigma-L1$pb(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+1(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+1(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	_sigma-L1$pb(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+2(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+3(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+3(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+2(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+4(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+5(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+5(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+4(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+6(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+7(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+7(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+6(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+8(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+9(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+9(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+8(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+10(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+11(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+11(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+10(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+12(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+13(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+13(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+12(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+14(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+15(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+15(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+14(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+16(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+17(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+17(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+16(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+18(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+19(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+19(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+18(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+20(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+21(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+21(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+20(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+22(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+23(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+23(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+22(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+24(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+25(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+25(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+24(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+26(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+27(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+27(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+26(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+28(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+29(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+29(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+28(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+30(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+31(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+31(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+30(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+32(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+33(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+33(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+32(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+34(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+35(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+35(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+34(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+36(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+37(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+37(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+36(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+38(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+39(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+39(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+38(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+40(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+41(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+41(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+40(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+42(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+43(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+43(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+42(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+44(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+45(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+45(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+44(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+46(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+47(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+47(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+46(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+48(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+49(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+49(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+48(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+50(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+51(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+51(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+50(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+52(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+53(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+53(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+52(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+54(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+55(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+55(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+54(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+56(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+57(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+57(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+56(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+58(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+59(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+59(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+58(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+60(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+61(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+61(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+60(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+62(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+63(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+63(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+62(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+64(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+65(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+65(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+64(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+66(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+67(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+67(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+66(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+68(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+69(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+69(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+68(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+70(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+71(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+71(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+70(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+72(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+73(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+73(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+72(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+74(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+75(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+75(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+74(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+76(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+77(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+77(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+76(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+78(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+79(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+79(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+78(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+80(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+81(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+81(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+80(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+82(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+83(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+83(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+82(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+84(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+85(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+85(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+84(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+86(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+87(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+87(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+86(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+88(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+89(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+89(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+88(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+90(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+91(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+91(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+90(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+92(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+93(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+93(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+92(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+94(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+95(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+95(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+94(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+96(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+97(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+97(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+96(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+98(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+99(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+99(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+98(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+100(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+101(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+101(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+100(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+102(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+103(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+103(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+102(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+104(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+105(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+105(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+104(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+106(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+107(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+107(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+106(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+108(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+109(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+109(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+108(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+110(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+111(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+111(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+110(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+112(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+113(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+113(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+112(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+114(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+115(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+115(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+114(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+116(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+117(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+117(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+116(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+118(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+119(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+119(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+118(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+120(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+121(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+121(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+120(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+122(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+123(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+123(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+122(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+124(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+125(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+125(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+124(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+126(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+127(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+127(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+126(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+128(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+129(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+129(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+128(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+130(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+131(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+131(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+130(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+132(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+133(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+133(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+132(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+134(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+135(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+135(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+134(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+136(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+137(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+137(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+136(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+138(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+139(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+139(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+138(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+140(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+141(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+141(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+140(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+142(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+143(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+143(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+142(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+144(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+145(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+145(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+144(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+146(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+147(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+147(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+146(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+148(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+149(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+149(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+148(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+150(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+151(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+151(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+150(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+152(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+153(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+153(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+152(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+154(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+155(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+155(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+154(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+156(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+157(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+157(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+156(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+158(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+159(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+159(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+158(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+160(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+161(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+161(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+160(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+162(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+163(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+163(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+162(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+164(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+165(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+165(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+164(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+166(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+167(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+167(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+166(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+168(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+169(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+169(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+168(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+170(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+171(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+171(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+170(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+172(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+173(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+173(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+172(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+174(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+175(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+175(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+174(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+176(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+177(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+177(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+176(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+178(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+179(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+179(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+178(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+180(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+181(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+181(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+180(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+182(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+183(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+183(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+182(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+184(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+185(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+185(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+184(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+186(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+187(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+187(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+186(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+188(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+189(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+189(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+188(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+190(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+191(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+191(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+190(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+192(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+193(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+193(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+192(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+194(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+195(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+195(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+194(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+196(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+197(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+197(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+196(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+198(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+199(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+199(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+198(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+200(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+201(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+201(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+200(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+202(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+203(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+203(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+202(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+204(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+205(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+205(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+204(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+206(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+207(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+207(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+206(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+208(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+209(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+209(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+208(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+210(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+211(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+211(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+210(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+212(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+213(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+213(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+212(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+214(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+215(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+215(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+214(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+216(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+217(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v0-L1$pb(%eax), %ecx
	movl	_v0-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v5-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+217(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+216(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v15-L1$pb(%eax), %ecx
	movl	_v15-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v0-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v10-L1$pb(%eax), %ecx
	movl	_v10-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v15-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v5-L1$pb(%eax), %ecx
	movl	_v5-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v10-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+218(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+219(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v1-L1$pb(%eax), %ecx
	movl	_v1-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v6-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+219(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+218(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v12-L1$pb(%eax), %ecx
	movl	_v12-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v1-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v11-L1$pb(%eax), %ecx
	movl	_v11-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v12-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v6-L1$pb(%eax), %ecx
	movl	_v6-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v11-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+220(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+221(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v2-L1$pb(%eax), %ecx
	movl	_v2-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v7-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+221(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+220(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v13-L1$pb(%eax), %ecx
	movl	_v13-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v2-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v8-L1$pb(%eax), %ecx
	movl	_v8-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v13-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v7-L1$pb(%eax), %ecx
	movl	_v7-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v8-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$7, %esi
	shll	$25, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+222(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+223(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$16, %esi
	shll	$16, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$12, %esi
	shll	$20, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v3-L1$pb(%eax), %ecx
	movl	_v3-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v4-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movb	(_sigma-L1$pb)+223(%eax), %bl
	movzbl	%bl, %esi
	movl	-16(%ebp), %edi
	movl	(%edi,%esi,4), %esi
	movb	(_sigma-L1$pb)+222(%eax), %bl
	movzbl	%bl, %edi
	movl	_c-L1$pb(%eax,%edi,4), %edi
	xorl	%edi, %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v14-L1$pb(%eax), %ecx
	movl	_v14-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v3-L1$pb(%eax), %esi
	movl	(%esi), %esi
	xorl	%esi, %edx
	movl	%edx, %esi
	shrl	$8, %esi
	shll	$24, %edx
	orl	%edx, %esi
	movl	%esi, (%ecx)
	movl	_v9-L1$pb(%eax), %ecx
	movl	_v9-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v14-L1$pb(%eax), %esi
	movl	(%esi), %esi
	addl	%esi, %edx
	movl	%edx, (%ecx)
	movl	_v4-L1$pb(%eax), %ecx
	movl	_v4-L1$pb(%eax), %edx
	movl	(%edx), %edx
	movl	_v9-L1$pb(%eax), %eax
	movl	(%eax), %eax
	xorl	%eax, %edx
	movl	%edx, %eax
	shrl	$7, %eax
	shll	$25, %edx
	orl	%edx, %eax
	movl	%eax, (%ecx)
	addl	$28, %esp
	popl	%esi
	popl	%edi
	popl	%ebx
	popl	%ebp
	ret

	.globl	_blake256
	.align	4, 0x90
_blake256:
	pushl	%ebp
	movl	%esp, %ebp
	pushl	%ebx
	pushl	%edi
	pushl	%esi
	subl	$268, %esp
	call	L2$pb
L2$pb:
	popl	%eax
	movl	20(%ebp), %ecx
	movl	16(%ebp), %edx
	movl	12(%ebp), %esi
	movl	8(%ebp), %edi
	movl	L___stack_chk_guard$non_lazy_ptr-L2$pb(%eax), %ebx
	movl	(%ebx), %ebx
	movl	%ebx, -16(%ebp)
	movl	%edi, -20(%ebp)
	movl	%esi, -24(%ebp)
	movl	%edx, -28(%ebp)
	movl	%ecx, -32(%ebp)
	movl	-24(%ebp), %ecx
	imull	$8, %ecx, %ecx
	andl	$511, %ecx
	movl	%ecx, -184(%ebp)
	movl	$0, -180(%ebp)
	movl	$0, -188(%ebp)
	movl	$0, -192(%ebp)
	movl	$0, -204(%ebp)
	leal	-204(%ebp), %ecx
	movl	-20(%ebp), %edx
	leal	-168(%ebp), %esi
	movl	-24(%ebp), %edi
	movl	%esp, %ebx
	movl	%esi, 16(%ebx)
	movl	%ecx, 12(%ebx)
	movl	%edi, 4(%ebx)
	movl	%edx, (%ebx)
	movl	$0, 8(%ebx)
	movl	%eax, -232(%ebp)
	call	_pad256
	movl	%edx, -196(%ebp)
	movl	%eax, -200(%ebp)
	movl	-32(%ebp), %eax
	movl	$1779033703, (%eax)
	movl	-32(%ebp), %eax
	movl	$-1150833019, 4(%eax)
	movl	-32(%ebp), %eax
	movl	$1013904242, 8(%eax)
	movl	-32(%ebp), %eax
	movl	$-1521486534, 12(%eax)
	movl	-32(%ebp), %eax
	movl	$1359893119, 16(%eax)
	movl	-32(%ebp), %eax
	movl	$-1694144372, 20(%eax)
	movl	-32(%ebp), %eax
	movl	$528734635, 24(%eax)
	movl	-32(%ebp), %eax
	movl	$1541459225, 28(%eax)
	movl	-200(%ebp), %eax
	movl	-196(%ebp), %ecx
	shldl	$6, %eax, %ecx
	movl	%ecx, -212(%ebp)
	shll	$6, %eax
	movl	%eax, -216(%ebp)
	movl	-20(%ebp), %eax
	movl	%eax, -228(%ebp)
	movl	$0, -220(%ebp)
	movl	$0, -224(%ebp)
	movl	$0, -172(%ebp)
	jmp	LBB2_2
LBB2_1:
	movl	-20(%ebp), %eax
	movl	-224(%ebp), %ecx
	movl	%ecx, %edx
	movzbl	(%eax,%edx), %eax
	shll	$24, %eax
	movl	-20(%ebp), %edx
	movl	%ecx, %esi
	movzbl	1(%edx,%esi), %esi
	shll	$16, %esi
	leal	(%eax,%esi), %eax
	movl	%ecx, %esi
	movzbl	2(%edx,%esi), %esi
	shll	$8, %esi
	leal	(%eax,%esi), %eax
	movzbl	3(%edx,%ecx), %ecx
	leal	(%eax,%ecx), %eax
	movl	-228(%ebp), %ecx
	movl	-172(%ebp), %edx
	movl	%eax, (%ecx,%edx,4)
	movl	-224(%ebp), %eax
	movl	-220(%ebp), %ecx
	addl	$4, %eax
	adcl	$0, %ecx
	movl	%ecx, -220(%ebp)
	movl	%eax, -224(%ebp)
	movl	-172(%ebp), %eax
	leal	1(%eax), %eax
	movl	%eax, -172(%ebp)
LBB2_2:
	movl	-216(%ebp), %eax
	movl	-212(%ebp), %ecx
	movl	-224(%ebp), %edx
	movl	-220(%ebp), %esi
	cmpl	%ecx, %esi
	sbbb	%bl, %bl
	andb	$1, %bl
	cmpl	%eax, %edx
	sbbb	%al, %al
	andb	$1, %al
	cmpl	%ecx, %esi
	movb	%al, -233(%ebp)
	movb	%bl, -234(%ebp)
	je	LBB2_17
	movb	-234(%ebp), %al
	movb	%al, %cl
	movb	%cl, -233(%ebp)
LBB2_17:
	movb	-233(%ebp), %al
	movb	%al, %cl
	testb	%cl, %cl
	jne	LBB2_1
	leal	-168(%ebp), %eax
	movl	%eax, -228(%ebp)
	movb	-168(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-167(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-166(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-165(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, (%ecx)
	movb	-164(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-163(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-162(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-161(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 4(%ecx)
	movb	-160(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-159(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-158(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-157(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 8(%ecx)
	movb	-156(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-155(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-154(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-153(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 12(%ecx)
	movb	-152(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-151(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-150(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-149(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 16(%ecx)
	movb	-148(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-147(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-146(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-145(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 20(%ecx)
	movb	-144(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-143(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-142(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-141(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 24(%ecx)
	movb	-140(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-139(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-138(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-137(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 28(%ecx)
	movb	-136(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-135(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-134(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-133(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 32(%ecx)
	movb	-132(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-131(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-130(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-129(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 36(%ecx)
	movb	-128(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-127(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-126(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-125(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 40(%ecx)
	movb	-124(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-123(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-122(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-121(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 44(%ecx)
	movb	-120(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-119(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-118(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-117(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 48(%ecx)
	movb	-116(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-115(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-114(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-113(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 52(%ecx)
	movb	-112(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-111(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-110(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-109(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 56(%ecx)
	movb	-108(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-107(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-106(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-105(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 60(%ecx)
	movb	-104(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-103(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-102(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-101(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 64(%ecx)
	movb	-100(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-99(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-98(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-97(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 68(%ecx)
	movb	-96(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-95(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-94(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-93(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 72(%ecx)
	movb	-92(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-91(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-90(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-89(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 76(%ecx)
	movb	-88(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-87(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-86(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-85(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 80(%ecx)
	movb	-84(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-83(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-82(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-81(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 84(%ecx)
	movb	-80(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-79(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-78(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-77(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 88(%ecx)
	movb	-76(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-75(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-74(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-73(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 92(%ecx)
	movb	-72(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-71(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-70(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-69(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 96(%ecx)
	movb	-68(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-67(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-66(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-65(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 100(%ecx)
	movb	-64(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-63(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-62(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-61(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 104(%ecx)
	movb	-60(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-59(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-58(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-57(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 108(%ecx)
	movb	-56(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-55(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-54(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-53(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 112(%ecx)
	movb	-52(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-51(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-50(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-49(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 116(%ecx)
	movb	-48(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-47(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-46(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-45(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 120(%ecx)
	movb	-44(%ebp), %al
	movzbl	%al, %eax
	shll	$24, %eax
	movb	-43(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$16, %ecx
	orl	%ecx, %eax
	movb	-42(%ebp), %cl
	movzbl	%cl, %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	movb	-41(%ebp), %cl
	movzbl	%cl, %ecx
	orl	%ecx, %eax
	movl	-228(%ebp), %ecx
	movl	%eax, 124(%ecx)
	movl	$0, -172(%ebp)
	jmp	LBB2_5
LBB2_4:
	leal	-192(%ebp), %eax
	movl	-192(%ebp), %ecx
	movl	-188(%ebp), %edx
	addl	$512, %ecx
	adcl	$0, %edx
	movl	%edx, -188(%ebp)
	movl	%ecx, -192(%ebp)
	movl	-28(%ebp), %ecx
	movl	-172(%ebp), %edx
	movl	-20(%ebp), %esi
	shll	$6, %edx
	leal	(%esi,%edx), %edx
	movl	-32(%ebp), %esi
	movl	%esp, %edi
	movl	%eax, 12(%edi)
	movl	%ecx, 8(%edi)
	movl	%edx, 4(%edi)
	movl	%esi, (%edi)
	call	_compress
	movl	-172(%ebp), %eax
	leal	1(%eax), %eax
	movl	%eax, -172(%ebp)
LBB2_5:
	movl	-172(%ebp), %eax
	movl	-200(%ebp), %ecx
	movl	-196(%ebp), %edx
	cmpl	%ecx, %eax
	sbbb	%al, %al
	andb	$1, %al
	testl	%edx, %edx
	setne	%cl
	movb	%al, -235(%ebp)
	movb	%cl, -236(%ebp)
	je	LBB2_19
	movb	-236(%ebp), %al
	movb	%al, %cl
	movb	%cl, -235(%ebp)
LBB2_19:
	movb	-235(%ebp), %al
	movb	%al, %cl
	testb	%cl, %cl
	jne	LBB2_4
	movl	-184(%ebp), %eax
	movl	-180(%ebp), %ecx
	orl	%ecx, %eax
	movl	%eax, -240(%ebp)
	je	LBB2_8
	leal	-192(%ebp), %eax
	movl	-184(%ebp), %ecx
	movl	-180(%ebp), %edx
	movl	-192(%ebp), %esi
	movl	-188(%ebp), %edi
	addl	%ecx, %esi
	adcl	%edx, %edi
	movl	%edi, -188(%ebp)
	movl	%esi, -192(%ebp)
	movl	-28(%ebp), %ecx
	leal	-168(%ebp), %edx
	movl	-32(%ebp), %esi
	movl	%esp, %edi
	movl	%eax, 12(%edi)
	movl	%ecx, 8(%edi)
	movl	%edx, 4(%edi)
	movl	%esi, (%edi)
	call	_compress
LBB2_8:
	movl	-204(%ebp), %eax
	cmpl	$1, %eax
	jne	LBB2_12
	movl	$0, -188(%ebp)
	movl	$0, -192(%ebp)
	movl	-184(%ebp), %eax
	movl	-180(%ebp), %ecx
	orl	%ecx, %eax
	movl	%eax, -244(%ebp)
	jne	LBB2_11
	leal	-192(%ebp), %eax
	movl	-28(%ebp), %ecx
	leal	-168(%ebp), %edx
	movl	-32(%ebp), %esi
	movl	%esi, (%esp)
	movl	%edx, 4(%esp)
	movl	%ecx, 8(%esp)
	movl	%eax, 12(%esp)
	call	_compress
	jmp	LBB2_12
LBB2_11:
	leal	-192(%ebp), %eax
	movl	-28(%ebp), %ecx
	leal	-168(%ebp), %edx
	addl	$64, %edx
	movl	-32(%ebp), %esi
	movl	%esi, (%esp)
	movl	%edx, 4(%esp)
	movl	%ecx, 8(%esp)
	movl	%eax, 12(%esp)
	call	_compress
LBB2_12:
	movl	-32(%ebp), %eax
	movl	%eax, -40(%ebp)
	movl	-40(%ebp), %eax
	movl	%eax, -36(%ebp)
	movl	-36(%ebp), %eax
	movl	-232(%ebp), %ecx
	movl	L___stack_chk_guard$non_lazy_ptr-L2$pb(%ecx), %edx
	movl	(%edx), %edx
	movl	-16(%ebp), %esi
	cmpl	%esi, %edx
	movl	%eax, -248(%ebp)
	jne	LBB2_15
	movl	-248(%ebp), %eax
	addl	$268, %esp
	popl	%esi
	popl	%edi
	popl	%ebx
	popl	%ebp
	ret
LBB2_15:
	call	___stack_chk_fail

	.align	4, 0x90
_compress:
	pushl	%ebp
	movl	%esp, %ebp
	pushl	%edi
	pushl	%esi
	subl	$32, %esp
	call	L3$pb
L3$pb:
	popl	%eax
	movl	20(%ebp), %ecx
	movl	16(%ebp), %edx
	movl	12(%ebp), %esi
	movl	8(%ebp), %edi
	movl	%edi, -12(%ebp)
	movl	%esi, -16(%ebp)
	movl	%edx, -20(%ebp)
	movl	%ecx, -24(%ebp)
	movl	_v0-L3$pb(%eax), %ecx
	movl	-12(%ebp), %edx
	movl	(%edx), %edx
	movl	%edx, (%ecx)
	movl	_v1-L3$pb(%eax), %ecx
	movl	-12(%ebp), %edx
	movl	4(%edx), %edx
	movl	%edx, (%ecx)
	movl	_v2-L3$pb(%eax), %ecx
	movl	-12(%ebp), %edx
	movl	8(%edx), %edx
	movl	%edx, (%ecx)
	movl	_v3-L3$pb(%eax), %ecx
	movl	-12(%ebp), %edx
	movl	12(%edx), %edx
	movl	%edx, (%ecx)
	movl	_v4-L3$pb(%eax), %ecx
	movl	-12(%ebp), %edx
	movl	16(%edx), %edx
	movl	%edx, (%ecx)
	movl	_v5-L3$pb(%eax), %ecx
	movl	-12(%ebp), %edx
	movl	20(%edx), %edx
	movl	%edx, (%ecx)
	movl	_v6-L3$pb(%eax), %ecx
	movl	-12(%ebp), %edx
	movl	24(%edx), %edx
	movl	%edx, (%ecx)
	movl	_v7-L3$pb(%eax), %ecx
	movl	-12(%ebp), %edx
	movl	28(%edx), %edx
	movl	%edx, (%ecx)
	movl	_v8-L3$pb(%eax), %ecx
	movl	-20(%ebp), %edx
	movl	(%edx), %edx
	xorl	$608135816, %edx
	movl	%edx, (%ecx)
	movl	_v9-L3$pb(%eax), %ecx
	movl	-20(%ebp), %edx
	movl	4(%edx), %edx
	xorl	$2242054355, %edx
	movl	%edx, (%ecx)
	movl	_v10-L3$pb(%eax), %ecx
	movl	-20(%ebp), %edx
	movl	8(%edx), %edx
	xorl	$320440878, %edx
	movl	%edx, (%ecx)
	movl	_v11-L3$pb(%eax), %ecx
	movl	-20(%ebp), %edx
	movl	12(%edx), %edx
	xorl	$57701188, %edx
	movl	%edx, (%ecx)
	movl	_v12-L3$pb(%eax), %ecx
	movl	-24(%ebp), %edx
	movl	(%edx), %edx
	xorl	$2752067618, %edx
	movl	%edx, (%ecx)
	movl	_v13-L3$pb(%eax), %ecx
	movl	-24(%ebp), %edx
	movl	(%edx), %edx
	xorl	$698298832, %edx
	movl	%edx, (%ecx)
	movl	_v14-L3$pb(%eax), %ecx
	movl	-24(%ebp), %edx
	movl	4(%edx), %edx
	xorl	$137296536, %edx
	movl	%edx, (%ecx)
	movl	_v15-L3$pb(%eax), %ecx
	movl	-24(%ebp), %edx
	movl	4(%edx), %edx
	xorl	$3964562569, %edx
	movl	%edx, (%ecx)
	movl	-16(%ebp), %ecx
	movl	%ecx, (%esp)
	movl	%eax, -28(%ebp)
	call	_rounds
	movl	-12(%ebp), %eax
	movl	(%eax), %eax
	movl	-20(%ebp), %ecx
	movl	(%ecx), %ecx
	xorl	%ecx, %eax
	movl	-28(%ebp), %ecx
	movl	_v0-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	_v8-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	-12(%ebp), %edx
	movl	%eax, (%edx)
	movl	-12(%ebp), %eax
	movl	4(%eax), %eax
	movl	-20(%ebp), %edx
	movl	4(%edx), %edx
	xorl	%edx, %eax
	movl	_v1-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	_v9-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	-12(%ebp), %edx
	movl	%eax, 4(%edx)
	movl	-12(%ebp), %eax
	movl	8(%eax), %eax
	movl	-20(%ebp), %edx
	movl	8(%edx), %edx
	xorl	%edx, %eax
	movl	_v2-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	_v10-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	-12(%ebp), %edx
	movl	%eax, 8(%edx)
	movl	-12(%ebp), %eax
	movl	12(%eax), %eax
	movl	-20(%ebp), %edx
	movl	12(%edx), %edx
	xorl	%edx, %eax
	movl	_v3-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	_v11-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	-12(%ebp), %edx
	movl	%eax, 12(%edx)
	movl	-12(%ebp), %eax
	movl	16(%eax), %eax
	movl	-20(%ebp), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	_v4-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	_v12-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	-12(%ebp), %edx
	movl	%eax, 16(%edx)
	movl	-12(%ebp), %eax
	movl	20(%eax), %eax
	movl	-20(%ebp), %edx
	movl	4(%edx), %edx
	xorl	%edx, %eax
	movl	_v5-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	_v13-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	-12(%ebp), %edx
	movl	%eax, 20(%edx)
	movl	-12(%ebp), %eax
	movl	24(%eax), %eax
	movl	-20(%ebp), %edx
	movl	8(%edx), %edx
	xorl	%edx, %eax
	movl	_v6-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	_v14-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	-12(%ebp), %edx
	movl	%eax, 24(%edx)
	movl	-12(%ebp), %eax
	movl	28(%eax), %eax
	movl	-20(%ebp), %edx
	movl	12(%edx), %edx
	xorl	%edx, %eax
	movl	_v7-L3$pb(%ecx), %edx
	movl	(%edx), %edx
	xorl	%edx, %eax
	movl	_v15-L3$pb(%ecx), %ecx
	movl	(%ecx), %ecx
	xorl	%ecx, %eax
	movl	-12(%ebp), %ecx
	movl	%eax, 28(%ecx)
	addl	$32, %esp
	popl	%esi
	popl	%edi
	popl	%ebp
	ret

	.align	4, 0x90
_pad256:
	pushl	%ebp
	movl	%esp, %ebp
	pushl	%edi
	pushl	%esi
	subl	$112, %esp
	movl	16(%ebp), %eax
	movl	12(%ebp), %ecx
	movl	24(%ebp), %edx
	movl	20(%ebp), %esi
	movl	8(%ebp), %edi
	movl	%edi, -12(%ebp)
	movl	%ecx, -24(%ebp)
	movl	%eax, -20(%ebp)
	movl	%esi, -28(%ebp)
	movl	%edx, -32(%ebp)
	movl	-24(%ebp), %eax
	movl	-20(%ebp), %ecx
	movl	%ecx, %edx
	shldl	$26, %eax, %edx
	shrl	$6, %ecx
	movl	%ecx, -68(%ebp)
	movl	%edx, -72(%ebp)
	movl	-24(%ebp), %eax
	movl	$0, -76(%ebp)
	andl	$63, %eax
	movl	%eax, -80(%ebp)
	movl	-12(%ebp), %ecx
	movl	-24(%ebp), %edx
	subl	%eax, %edx
	leal	(%ecx,%edx), %eax
	movl	%eax, -92(%ebp)
	jmp	LBB4_2
	movl	-32(%ebp), %eax
	movl	$-1, %eax
	movl	-32(%ebp), %ecx
	movl	-92(%ebp), %edx
	movl	-80(%ebp), %esi
	movl	%esp, %edi
	movl	%eax, 12(%edi)
	movl	%esi, 8(%edi)
	movl	%edx, 4(%edi)
	movl	%ecx, (%edi)
	call	___memcpy_chk
	movl	%eax, -64(%ebp)
	jmp	LBB4_3
LBB4_2:
	movl	-32(%ebp), %eax
	movl	-92(%ebp), %ecx
	movl	-80(%ebp), %edx
	movl	%esp, %esi
	movl	%edx, 8(%esi)
	movl	%ecx, 4(%esi)
	movl	%eax, (%esi)
	call	___inline_memcpy_chk
	movl	%eax, -64(%ebp)
LBB4_3:
	movl	-32(%ebp), %eax
	movl	%eax, -92(%ebp)
	movl	-92(%ebp), %eax
	movl	-80(%ebp), %ecx
	leal	(%eax,%ecx), %eax
	movl	%eax, -96(%ebp)
	movl	-80(%ebp), %eax
	movl	-76(%ebp), %ecx
	orl	%ecx, %eax
	movl	%eax, -100(%ebp)
	jne	LBB4_8
	movl	$0, -84(%ebp)
	movl	$54, -88(%ebp)
	movl	-28(%ebp), %eax
	movl	$1, (%eax)
	movl	-96(%ebp), %eax
	movb	$-128, (%eax)
	movl	-96(%ebp), %eax
	leal	1(%eax), %eax
	movl	%eax, -96(%ebp)
	jmp	LBB4_6
	movl	-96(%ebp), %eax
	movl	$-1, %eax
	movl	-96(%ebp), %ecx
	movl	-88(%ebp), %edx
	movl	%esp, %esi
	movl	%eax, 12(%esi)
	movl	%edx, 8(%esi)
	movl	%ecx, (%esi)
	movl	$0, 4(%esi)
	call	___memset_chk
	movl	%eax, -60(%ebp)
	jmp	LBB4_7
LBB4_6:
	movl	-96(%ebp), %eax
	movl	-88(%ebp), %ecx
	movl	%esp, %edx
	movl	%ecx, 8(%edx)
	movl	%eax, (%edx)
	movl	$0, 4(%edx)
	call	___inline_memset_chk
	movl	%eax, -60(%ebp)
LBB4_7:
	movl	-96(%ebp), %eax
	movl	-88(%ebp), %ecx
	movb	$1, (%eax,%ecx)
	movl	-96(%ebp), %eax
	leal	1(%eax), %ecx
	movl	%ecx, -96(%ebp)
	movl	-88(%ebp), %ecx
	leal	1(%eax,%ecx), %eax
	movl	-24(%ebp), %ecx
	movl	-20(%ebp), %edx
	shldl	$3, %ecx, %edx
	movl	%esp, %esi
	movl	%edx, 8(%esi)
	leal	(,%ecx,8), %ecx
	movl	%ecx, 4(%esi)
	movl	%eax, (%esi)
	call	_dumpLen
	jmp	LBB4_19
LBB4_8:
	movl	-80(%ebp), %eax
	movl	-76(%ebp), %ecx
	cmpl	$54, %eax
	seta	%al
	testl	%ecx, %ecx
	setne	%cl
	movb	%al, -101(%ebp)
	movb	%cl, -102(%ebp)
	je	LBB4_22
	movb	-102(%ebp), %al
	movb	%al, %cl
	movb	%cl, -101(%ebp)
LBB4_22:
	movb	-101(%ebp), %al
	movb	%al, %cl
	testb	%cl, %cl
	jne	LBB4_13
	movl	-80(%ebp), %eax
	movl	-76(%ebp), %ecx
	xorl	%edx, %edx
	movl	$54, %esi
	subl	%eax, %esi
	sbbl	%ecx, %edx
	movl	%edx, -84(%ebp)
	movl	%esi, -88(%ebp)
	movl	-96(%ebp), %eax
	movb	$-128, (%eax)
	movl	-96(%ebp), %eax
	leal	1(%eax), %eax
	movl	%eax, -96(%ebp)
	jmp	LBB4_11
	movl	-96(%ebp), %eax
	movl	$-1, %eax
	movl	-96(%ebp), %ecx
	movl	-88(%ebp), %edx
	movl	%esp, %esi
	movl	%eax, 12(%esi)
	movl	%edx, 8(%esi)
	movl	%ecx, (%esi)
	movl	$0, 4(%esi)
	call	___memset_chk
	movl	%eax, -56(%ebp)
	jmp	LBB4_12
LBB4_11:
	movl	-96(%ebp), %eax
	movl	-88(%ebp), %ecx
	movl	%esp, %edx
	movl	%ecx, 8(%edx)
	movl	%eax, (%edx)
	movl	$0, 4(%edx)
	call	___inline_memset_chk
	movl	%eax, -56(%ebp)
LBB4_12:
	movl	-96(%ebp), %eax
	movl	-88(%ebp), %ecx
	movb	$1, (%eax,%ecx)
	movl	-96(%ebp), %eax
	leal	1(%eax), %ecx
	movl	%ecx, -96(%ebp)
	movl	-88(%ebp), %ecx
	leal	1(%eax,%ecx), %eax
	movl	-24(%ebp), %ecx
	movl	-20(%ebp), %edx
	shldl	$3, %ecx, %edx
	movl	%esp, %esi
	movl	%edx, 8(%esi)
	leal	(,%ecx,8), %ecx
	movl	%ecx, 4(%esi)
	movl	%eax, (%esi)
	call	_dumpLen
	jmp	LBB4_19
LBB4_13:
	movl	-80(%ebp), %eax
	movl	-76(%ebp), %ecx
	cmpl	$56, %eax
	sbbb	%al, %al
	andb	$1, %al
	xorb	%dl, %dl
	testl	%ecx, %ecx
	movb	%al, -103(%ebp)
	movb	%dl, -104(%ebp)
	je	LBB4_24
	movb	-104(%ebp), %al
	movb	%al, %cl
	movb	%cl, -103(%ebp)
LBB4_24:
	movb	-103(%ebp), %al
	movb	%al, %cl
	testb	%cl, %cl
	jne	LBB4_18
	movl	-28(%ebp), %eax
	movl	$1, (%eax)
	movl	-80(%ebp), %eax
	movl	-76(%ebp), %ecx
	xorl	%edx, %edx
	movl	$118, %esi
	subl	%eax, %esi
	sbbl	%ecx, %edx
	movl	%edx, -84(%ebp)
	movl	%esi, -88(%ebp)
	movl	-96(%ebp), %eax
	movb	$-128, (%eax)
	movl	-96(%ebp), %eax
	leal	1(%eax), %eax
	movl	%eax, -96(%ebp)
	jmp	LBB4_16
	movl	-96(%ebp), %eax
	movl	$-1, %eax
	movl	-96(%ebp), %ecx
	movl	-88(%ebp), %edx
	movl	%esp, %esi
	movl	%eax, 12(%esi)
	movl	%edx, 8(%esi)
	movl	%ecx, (%esi)
	movl	$0, 4(%esi)
	call	___memset_chk
	movl	%eax, -52(%ebp)
	jmp	LBB4_17
LBB4_16:
	movl	-96(%ebp), %eax
	movl	-88(%ebp), %ecx
	movl	%esp, %edx
	movl	%ecx, 8(%edx)
	movl	%eax, (%edx)
	movl	$0, 4(%edx)
	call	___inline_memset_chk
	movl	%eax, -52(%ebp)
LBB4_17:
	movl	-96(%ebp), %eax
	movl	-88(%ebp), %ecx
	movb	$1, (%eax,%ecx)
	movl	-96(%ebp), %eax
	leal	1(%eax), %ecx
	movl	%ecx, -96(%ebp)
	movl	-88(%ebp), %ecx
	leal	1(%eax,%ecx), %eax
	movl	-24(%ebp), %ecx
	movl	-20(%ebp), %edx
	shldl	$3, %ecx, %edx
	movl	%esp, %esi
	movl	%edx, 8(%esi)
	leal	(,%ecx,8), %ecx
	movl	%ecx, 4(%esi)
	movl	%eax, (%esi)
	call	_dumpLen
	jmp	LBB4_19
LBB4_18:
	movl	-92(%ebp), %eax
	movl	-80(%ebp), %ecx
	movb	$-127, (%eax,%ecx)
	movl	-92(%ebp), %eax
	movl	-80(%ebp), %ecx
	leal	1(%eax,%ecx), %eax
	movl	-24(%ebp), %ecx
	movl	-20(%ebp), %edx
	shldl	$3, %ecx, %edx
	movl	%esp, %esi
	movl	%edx, 8(%esi)
	leal	(,%ecx,8), %ecx
	movl	%ecx, 4(%esi)
	movl	%eax, (%esi)
	call	_dumpLen
LBB4_19:
	movsd	-72(%ebp), %xmm0
	movsd	%xmm0, -48(%ebp)
	movsd	%xmm0, -40(%ebp)
	movl	-40(%ebp), %eax
	movl	-36(%ebp), %ecx
	movl	%ecx, %edx
	addl	$112, %esp
	popl	%esi
	popl	%edi
	popl	%ebp
	ret

	.align	4, 0x90
___inline_memcpy_chk:
	pushl	%ebp
	movl	%esp, %ebp
	pushl	%esi
	subl	$36, %esp
	movl	16(%ebp), %eax
	movl	12(%ebp), %ecx
	movl	8(%ebp), %edx
	movl	%edx, -8(%ebp)
	movl	%ecx, -12(%ebp)
	movl	%eax, -16(%ebp)
	movl	-8(%ebp), %eax
	movl	$-1, %eax
	movl	-8(%ebp), %ecx
	movl	-12(%ebp), %ecx
	movl	-16(%ebp), %ecx
	movl	-8(%ebp), %ecx
	movl	-12(%ebp), %edx
	movl	-16(%ebp), %esi
	movl	%ecx, (%esp)
	movl	%edx, 4(%esp)
	movl	%esi, 8(%esp)
	movl	%eax, 12(%esp)
	call	___memcpy_chk
	movl	%eax, -24(%ebp)
	movl	-24(%ebp), %eax
	movl	%eax, -20(%ebp)
	movl	-20(%ebp), %eax
	addl	$36, %esp
	popl	%esi
	popl	%ebp
	ret

	.align	4, 0x90
___inline_memset_chk:
	pushl	%ebp
	movl	%esp, %ebp
	pushl	%esi
	subl	$36, %esp
	movl	16(%ebp), %eax
	movl	12(%ebp), %ecx
	movl	8(%ebp), %edx
	movl	%edx, -8(%ebp)
	movl	%ecx, -12(%ebp)
	movl	%eax, -16(%ebp)
	movl	-8(%ebp), %eax
	movl	$-1, %eax
	movl	-8(%ebp), %ecx
	movl	-12(%ebp), %ecx
	movl	-16(%ebp), %ecx
	movl	-8(%ebp), %ecx
	movl	-12(%ebp), %edx
	movl	-16(%ebp), %esi
	movl	%ecx, (%esp)
	movl	%edx, 4(%esp)
	movl	%esi, 8(%esp)
	movl	%eax, 12(%esp)
	call	___memset_chk
	movl	%eax, -24(%ebp)
	movl	-24(%ebp), %eax
	movl	%eax, -20(%ebp)
	movl	-20(%ebp), %eax
	addl	$36, %esp
	popl	%esi
	popl	%ebp
	ret

	.section	__TEXT,__const
	.align	5
_c256:
	.long	608135816
	.long	2242054355
	.long	320440878
	.long	57701188
	.long	2752067618
	.long	698298832
	.long	137296536
	.long	3964562569
	.long	1160258022
	.long	953160567
	.long	3193202383
	.long	887688300
	.long	3232508343
	.long	3380367581
	.long	1065670069
	.long	3041331479

	.align	5
_sigma:
	.ascii	 "\000\001\002\003\004\005\006\007\b\t\n\013\f\r\016\017"
	.ascii	 "\016\n\004\b\t\017\r\006\001\f\000\002\013\007\005\003"
	.ascii	 "\013\b\f\000\005\002\017\r\n\016\003\006\007\001\t\004"
	.ascii	 "\007\t\003\001\r\f\013\016\002\006\005\n\004\000\017\b"
	.ascii	 "\t\000\005\007\002\004\n\017\016\001\013\f\006\b\003\r"
	.ascii	 "\002\f\006\n\000\013\b\003\004\r\007\005\017\016\001\t"
	.ascii	 "\f\005\001\017\016\r\004\n\000\007\006\003\t\002\b\013"
	.ascii	 "\r\013\007\016\f\001\003\t\005\000\017\004\b\006\002\n"
	.ascii	 "\006\017\016\t\013\003\000\b\f\002\r\007\001\004\n\005"
	.asciz	 "\n\002\b\004\007\006\001\005\017\013\t\016\003\f\r"
	.ascii	 "\000\001\002\003\004\005\006\007\b\t\n\013\f\r\016\017"
	.ascii	 "\016\n\004\b\t\017\r\006\001\f\000\002\013\007\005\003"
	.ascii	 "\013\b\f\000\005\002\017\r\n\016\003\006\007\001\t\004"
	.ascii	 "\007\t\003\001\r\f\013\016\002\006\005\n\004\000\017\b"
	.ascii	 "\t\000\005\007\002\004\n\017\016\001\013\f\006\b\003\r"
	.ascii	 "\002\f\006\n\000\013\b\003\004\r\007\005\017\016\001\t"
	.ascii	 "\f\005\001\017\016\r\004\n\000\007\006\003\t\002\b\013"
	.ascii	 "\r\013\007\016\f\001\003\t\005\000\017\004\b\006\002\n"
	.ascii	 "\006\017\016\t\013\003\000\b\f\002\r\007\001\004\n\005"
	.asciz	 "\n\002\b\004\007\006\001\005\017\013\t\016\003\f\r"

	.align	5
_c:
	.long	608135816
	.long	2242054355
	.long	320440878
	.long	57701188
	.long	2752067618
	.long	698298832
	.long	137296536
	.long	3964562569
	.long	1160258022
	.long	953160567
	.long	3193202383
	.long	887688300
	.long	3232508343
	.long	3380367581
	.long	1065670069
	.long	3041331479

	.section	__DATA,__data
	.align	2
_v0:
	.long	_state32

.zerofill __DATA,__bss,_state32,64,5
	.align	2
_v1:
	.long	_state32+4

	.align	2
_v2:
	.long	_state32+8

	.align	2
_v3:
	.long	_state32+12

	.align	2
_v4:
	.long	_state32+16

	.align	2
_v5:
	.long	_state32+20

	.align	2
_v6:
	.long	_state32+24

	.align	2
_v7:
	.long	_state32+28

	.align	2
_v8:
	.long	_state32+32

	.align	2
_v9:
	.long	_state32+36

	.align	2
_v10:
	.long	_state32+40

	.align	2
_v11:
	.long	_state32+44

	.align	2
_v12:
	.long	_state32+48

	.align	2
_v13:
	.long	_state32+52

	.align	2
_v14:
	.long	_state32+56

	.align	2
_v15:
	.long	_state32+60


	.section	__IMPORT,__pointers,non_lazy_symbol_pointers
L___stack_chk_guard$non_lazy_ptr:
.indirect_symbol ___stack_chk_guard
	.long	0

.subsections_via_symbols
